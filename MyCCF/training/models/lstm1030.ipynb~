{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集前5条数据:\n",
      "     user_id        date  steps  exercise_time  avg_heart_rate  \\\n",
      "453        2  2024-07-02  16017            106             107   \n",
      "793        3  2024-06-25   3134             37             155   \n",
      "209        1  2024-04-04   4930             78             109   \n",
      "309        1  2023-12-26   7520            116             167   \n",
      "740        3  2024-08-17   2221             53             115   \n",
      "\n",
      "     max_heart_rate  sleep_duration  fatigue_level  relaxation_training  \\\n",
      "453             122        8.696292              7                    0   \n",
      "793             168        5.329202              7                    0   \n",
      "209             118        6.768598              6                    0   \n",
      "309             184        4.303134              9                    1   \n",
      "740             142        9.474783              5                    0   \n",
      "\n",
      "     height  weight  age  \n",
      "453     180      80   25  \n",
      "793     165      65   35  \n",
      "209     175      70   30  \n",
      "309     175      70   30  \n",
      "740     165      65   35  \n",
      "\n",
      "验证集前5条数据:\n",
      "    user_id        date  steps  exercise_time  avg_heart_rate  max_heart_rate  \\\n",
      "1         1  2024-10-29   3750             27             162             187   \n",
      "4         1  2024-10-26   6164             58             129             145   \n",
      "13        1  2024-10-17   7261             82             161             185   \n",
      "14        1  2024-10-16   9555            115             152             152   \n",
      "20        1  2024-10-10  12092             52              81              99   \n",
      "\n",
      "    sleep_duration  fatigue_level  relaxation_training  height  weight  age  \n",
      "1         9.654181              5                    0     175      70   30  \n",
      "4         7.078538              5                    0     175      70   30  \n",
      "13        6.024281              9                    1     175      70   30  \n",
      "14        8.934772              4                    0     175      70   30  \n",
      "20        8.676484              6                    0     175      70   30  \n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 生成模拟数据，三个人固定的身高、体重和年龄，每个人333条数据\n",
    "def generate_fixed_data_with_dates(num_users=3, num_records_per_user=333, noise_level=0.05):\n",
    "    user_ids = range(1, num_users + 1)\n",
    "    \n",
    "    # 为每个人分配固定的身高、体重和年龄\n",
    "    fixed_heights = [175, 180, 165]  # 三个人的固定身高\n",
    "    fixed_weights = [70, 80, 65]     # 三个人的固定体重\n",
    "    fixed_ages = [30, 25, 35]        # 三个人的固定年龄\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        # 为每个人生成333天前到今天的日期\n",
    "        dates = [datetime.now() - timedelta(days=i) for i in range(num_records_per_user)]\n",
    "        for date in dates:\n",
    "            steps = np.random.randint(1000, 20000)\n",
    "            exercise_time = np.random.randint(10, 120)\n",
    "            avg_heart_rate = np.random.randint(60, 180)\n",
    "            max_heart_rate = avg_heart_rate + np.random.randint(5, 30)\n",
    "            sleep_duration = np.random.uniform(4, 10)\n",
    "            fatigue_level = np.random.randint(1, 10)\n",
    "            relaxation_training = 1 if fatigue_level > 7 else 0\n",
    "\n",
    "            # 添加高斯噪声\n",
    "            steps += int(np.random.normal(0, noise_level * steps))\n",
    "            exercise_time += int(np.random.normal(0, noise_level * exercise_time))\n",
    "            avg_heart_rate += int(np.random.normal(0, noise_level * avg_heart_rate))\n",
    "            max_heart_rate += int(np.random.normal(0, noise_level * max_heart_rate))\n",
    "            sleep_duration += np.random.normal(0, noise_level * sleep_duration)\n",
    "\n",
    "            # 使用用户的固定身高、体重和年龄\n",
    "            height = fixed_heights[user_id - 1]\n",
    "            weight = fixed_weights[user_id - 1]\n",
    "            age = fixed_ages[user_id - 1]\n",
    "\n",
    "            # 添加数据到列表中\n",
    "            data.append([\n",
    "                user_id, date.strftime('%Y-%m-%d'), steps, exercise_time, avg_heart_rate, \n",
    "                max_heart_rate, sleep_duration, fatigue_level, relaxation_training, \n",
    "                height, weight, age\n",
    "            ])\n",
    "    \n",
    "    columns = [\n",
    "        'user_id', 'date', 'steps', 'exercise_time', 'avg_heart_rate', \n",
    "        'max_heart_rate', 'sleep_duration', 'fatigue_level', \n",
    "        'relaxation_training', 'height', 'weight', 'age'\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# 生成3个用户，每个用户333条数据，总共999条数据\n",
    "df = generate_fixed_data_with_dates()\n",
    "\n",
    "# 划分训练集和验证集\n",
    "def split_data(df, train_ratio=0.8):\n",
    "    # 按比例划分训练集和验证集\n",
    "    train_df = df.sample(frac=train_ratio, random_state=42)  # 随机抽取80%的数据作为训练集\n",
    "    val_df = df.drop(train_df.index)  # 剩下的20%作为验证集\n",
    "    return train_df, val_df\n",
    "\n",
    "# 将数据划分为训练集和验证集\n",
    "train_df, val_df = split_data(df)\n",
    "\n",
    "# 保存数据到CSV文件\n",
    "train_df.to_csv('train_data_with_noise.csv', index=False)\n",
    "val_df.to_csv('val_data_with_noise.csv', index=False)\n",
    "\n",
    "# 查看部分生成的数据\n",
    "print(\"训练集前5条数据:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\n验证集前5条数据:\")\n",
    "print(val_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成滑动窗口数据\n",
    "def create_sliding_window_data(df, window_size=14):\n",
    "    X, y = [], []\n",
    "    \n",
    "    # 对每个用户单独处理\n",
    "    for user_id in df['user_id'].unique():\n",
    "        user_data = df[df['user_id'] == user_id].sort_values(by='date')\n",
    "        features = user_data[['steps', 'exercise_time', 'avg_heart_rate', 'max_heart_rate', \n",
    "                              'sleep_duration', 'fatigue_level', \n",
    "                              'height', 'weight', 'age']]\n",
    "        target = user_data['relaxation_training']  # 目标是 relaxation_training\n",
    "        \n",
    "        # 使用滑动窗口生成数据\n",
    "        for i in range(len(user_data) - window_size):\n",
    "            X.append(features.iloc[i:i+window_size].values)  # 14天的输入数据\n",
    "            y.append(target.iloc[i+window_size])  # 第15天的目标值\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 X 维度: (605, 14, 9)\n",
      "训练集 y 维度: (605,)\n",
      "验证集 X 维度: (152, 14, 9)\n",
      "验证集 y 维度: (152,)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "df = pd.read_csv('train_data_with_noise.csv')  # 假设你的数据在这个文件中\n",
    "\n",
    "# 处理滑动窗口\n",
    "window_size = 14\n",
    "X, y = create_sliding_window_data(df, window_size=window_size)\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "num_features = X.shape[2]  # 特征数量\n",
    "X_reshaped = X.reshape(-1, num_features)  # 调整为二维\n",
    "X_scaled = scaler.fit_transform(X_reshaped)  # 标准化\n",
    "X_scaled = X_scaled.reshape(X.shape)  # 调整回三维\n",
    "\n",
    "# 划分训练集和验证集（80%训练集，20%验证集）\n",
    "train_size = int(len(X_scaled) * 0.8)\n",
    "train_X, val_X = X_scaled[:train_size], X_scaled[train_size:]\n",
    "train_y, val_y = y[:train_size], y[train_size:]\n",
    "\n",
    "# 打印数据维度\n",
    "print(\"训练集 X 维度:\", train_X.shape)  # (num_samples, window_size, num_features)\n",
    "print(\"训练集 y 维度:\", train_y.shape)  # (num_samples,)\n",
    "print(\"验证集 X 维度:\", val_X.shape)\n",
    "print(\"验证集 y 维度:\", val_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为 PyTorch 张量\n",
    "train_X_tensor = torch.tensor(train_X, dtype=torch.float32)\n",
    "train_y_tensor = torch.tensor(train_y, dtype=torch.float32)\n",
    "val_X_tensor = torch.tensor(val_X, dtype=torch.float32)\n",
    "val_y_tensor = torch.tensor(val_y, dtype=torch.float32)\n",
    "\n",
    "# 创建训练集和验证集的 TensorDataset\n",
    "train_dataset = TensorDataset(train_X_tensor, train_y_tensor)\n",
    "val_dataset = TensorDataset(val_X_tensor, val_y_tensor)\n",
    "\n",
    "# 创建 DataLoader\n",
    "batch_size = 64  # 批大小\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMModel(\n",
      "  (lstm): LSTM(9, 64, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        out = self.fc(hn[-1])  # 使用最后一层的最后一个时间步的隐状态\n",
    "        return out\n",
    "\n",
    "# 定义超参数\n",
    "input_size = 9  # 输入的特征数\n",
    "hidden_size = 64  # 隐藏层神经元数量\n",
    "num_layers = 2  # LSTM的层数\n",
    "output_size = 1  # 输出是一个标量\n",
    "\n",
    "# 实例化模型\n",
    "model = LSTMModel(input_size=input_size, hidden_size=hidden_size, \n",
    "                  num_layers=num_layers, output_size=output_size)\n",
    "\n",
    "# 打印模型架构\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.1614\n",
      "Epoch [2/30], Loss: 0.1644\n",
      "Epoch [3/30], Loss: 0.1614\n",
      "Epoch [4/30], Loss: 0.1622\n",
      "Epoch [5/30], Loss: 0.1660\n",
      "Epoch [6/30], Loss: 0.1570\n",
      "Epoch [7/30], Loss: 0.1648\n",
      "Epoch [8/30], Loss: 0.1612\n",
      "Epoch [9/30], Loss: 0.1580\n",
      "Epoch [10/30], Loss: 0.1587\n",
      "Epoch [11/30], Loss: 0.1540\n",
      "Epoch [12/30], Loss: 0.1521\n",
      "Epoch [13/30], Loss: 0.1509\n",
      "Epoch [14/30], Loss: 0.1505\n",
      "Epoch [15/30], Loss: 0.1500\n",
      "Epoch [16/30], Loss: 0.1471\n",
      "Epoch [17/30], Loss: 0.1452\n",
      "Epoch [18/30], Loss: 0.1423\n",
      "Epoch [19/30], Loss: 0.1364\n",
      "Epoch [20/30], Loss: 0.1300\n",
      "Epoch [21/30], Loss: 0.1284\n",
      "Epoch [22/30], Loss: 0.1272\n",
      "Epoch [23/30], Loss: 0.1254\n",
      "Epoch [24/30], Loss: 0.1193\n",
      "Epoch [25/30], Loss: 0.1144\n",
      "Epoch [26/30], Loss: 0.1124\n",
      "Epoch [27/30], Loss: 0.1052\n",
      "Epoch [28/30], Loss: 0.0979\n",
      "Epoch [29/30], Loss: 0.0879\n",
      "Epoch [30/30], Loss: 0.0861\n",
      "Validation Loss: 0.2068\n"
     ]
    }
   ],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()  # 使用均方误差\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "# 训练模型\n",
    "num_epochs = 30  # 训练的轮数\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 切换到训练模式\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# 验证模型\n",
    "model.eval()  # 切换到评估模式\n",
    "val_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.squeeze(), targets)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydemo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
